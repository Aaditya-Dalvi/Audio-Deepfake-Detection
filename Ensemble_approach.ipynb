{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "935abca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac00fcb",
   "metadata": {},
   "source": [
    "### Configuration and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffe7f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = r\"D:\\BE Project\\Self\\MAIN DATASET\"\n",
    "SPECTROGRAM_DIR = r\"D:\\BE Project\\Self\\APPROACH3-CNN-BiLSTM\\spectrograms\"\n",
    "EMBEDDING_DIR = r\"D:\\BE Project\\Self\\APPROACH3-CNN-BiLSTM\\embeddings\"\n",
    "MODEL_DIR = r\"D:\\BE Project\\Self\\APPROACH3-CNN-BiLSTM\\models\"\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [SPECTROGRAM_DIR, EMBEDDING_DIR, MODEL_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Audio processing parameters\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION = 3  # seconds\n",
    "SEGMENT_SAMPLES = SAMPLE_RATE * DURATION\n",
    "N_MELS = 128\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57eea9c",
   "metadata": {},
   "source": [
    "### Data Preprocessing - Generate Spectrograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f333f883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating spectrograms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:29<00:00, 27.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrogram generation complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_spectrograms():\n",
    "    \"\"\"Generate mel-spectrograms from audio files\"\"\"\n",
    "    print(\"Generating spectrograms...\")\n",
    "    \n",
    "    for file in tqdm(os.listdir(AUDIO_DIR)):\n",
    "        if not file.endswith(\".wav\"):\n",
    "            continue\n",
    "            \n",
    "        file_path = os.path.join(AUDIO_DIR, file)\n",
    "        \n",
    "        # Determine label from filename\n",
    "        # Assumes 'fake' in filename = fake (1), otherwise real (0)\n",
    "        label = 1 if \"fake\" in file.lower() else 0\n",
    "        \n",
    "        try:\n",
    "            # Load and preprocess audio\n",
    "            y, sr = librosa.load(file_path, sr=SAMPLE_RATE, mono=True)\n",
    "            y = librosa.util.fix_length(y, size=SEGMENT_SAMPLES)\n",
    "            \n",
    "            # Generate mel-spectrogram\n",
    "            mel_spec = librosa.feature.melspectrogram(\n",
    "                y=y, sr=sr, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH\n",
    "            )\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            \n",
    "            # Save spectrogram\n",
    "            out_name = os.path.splitext(file)[0] + \".npy\"\n",
    "            np.save(\n",
    "                os.path.join(SPECTROGRAM_DIR, out_name), \n",
    "                {\"spec\": mel_spec_db, \"label\": label, \"filename\": file}\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "    \n",
    "    print(\"Spectrogram generation complete!\")\n",
    "\n",
    "# Generate spectrograms\n",
    "generate_spectrograms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216b62cf",
   "metadata": {},
   "source": [
    "### Data Preprocessing - Generate wav2vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3c200f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wav2vec 2.0 model\n",
    "bundle = torchaudio.pipelines.WAV2VEC2_BASE\n",
    "model_wav2vec = bundle.get_model().to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc559fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating wav2vec embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [13:37<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_wav2vec_embedding(audio_path):\n",
    "    \"\"\"Extract wav2vec embedding from audio file\"\"\"\n",
    "    waveform, sr = torchaudio.load(audio_path)\n",
    "    \n",
    "    # Convert to mono if stereo\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    # Resample if necessary\n",
    "    if sr != bundle.sample_rate:\n",
    "        waveform = torchaudio.transforms.Resample(sr, bundle.sample_rate)(waveform)\n",
    "    \n",
    "    waveform = waveform.to(device)\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        features, _ = model_wav2vec(waveform)\n",
    "        # Average across time dimension\n",
    "        embedding = features.mean(dim=1).squeeze().cpu().numpy()\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "def generate_embeddings():\n",
    "    \"\"\"Generate wav2vec embeddings from audio files\"\"\"\n",
    "    print(\"Generating wav2vec embeddings...\")\n",
    "    \n",
    "    for file in tqdm(os.listdir(AUDIO_DIR)):\n",
    "        if not file.endswith(\".wav\"):\n",
    "            continue\n",
    "            \n",
    "        file_path = os.path.join(AUDIO_DIR, file)\n",
    "        label = 1 if \"fake\" in file.lower() else 0\n",
    "        \n",
    "        try:\n",
    "            embedding = extract_wav2vec_embedding(file_path)\n",
    "            \n",
    "            # Save embedding\n",
    "            out_name = os.path.splitext(file)[0] + \".npy\"\n",
    "            np.save(\n",
    "                os.path.join(EMBEDDING_DIR, out_name),\n",
    "                {\"embedding\": embedding, \"label\": label, \"filename\": file}\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "    \n",
    "    print(\"Embedding generation complete!\")\n",
    "\n",
    "# Generate embeddings\n",
    "generate_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52450d82",
   "metadata": {},
   "source": [
    "### Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c475f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, spec_dir):\n",
    "        self.paths = [\n",
    "            os.path.join(spec_dir, fname) \n",
    "            for fname in os.listdir(spec_dir) \n",
    "            if fname.endswith(\".npy\")\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.paths[idx], allow_pickle=True).item()\n",
    "        spec = data[\"spec\"]\n",
    "        label = data[\"label\"]\n",
    "        \n",
    "        # Normalize spectrogram\n",
    "        spec = (spec - spec.mean()) / (spec.std() + 1e-8)\n",
    "        spec_tensor = torch.tensor(spec, dtype=torch.float32).unsqueeze(0)  # [1, Mel, Time]\n",
    "        \n",
    "        return spec_tensor, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embedding_dir):\n",
    "        self.paths = [\n",
    "            os.path.join(embedding_dir, fname)\n",
    "            for fname in os.listdir(embedding_dir)\n",
    "            if fname.endswith(\".npy\")\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.paths[idx], allow_pickle=True).item()\n",
    "        embedding = data[\"embedding\"]\n",
    "        label = data[\"label\"]\n",
    "        \n",
    "        return torch.tensor(embedding, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f903354",
   "metadata": {},
   "source": [
    "### Model Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56f5e43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class CNN_BiLSTM(nn.Module):\n",
    "    def __init__(self, n_mels=128):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "        )\n",
    "        \n",
    "        # Calculate LSTM input size\n",
    "        lstm_input_size = 64 * (n_mels // 8)  # After 3 maxpool operations\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_size, \n",
    "            hidden_size=128, \n",
    "            batch_first=True, \n",
    "            bidirectional=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256, 128),  # 256 because bidirectional\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN feature extraction\n",
    "        x = self.cnn(x)  # [B, 64, Mel/8, Time/8]\n",
    "        \n",
    "        # Prepare for LSTM: [B, Time, Features]\n",
    "        x = x.permute(0, 3, 1, 2)  # [B, Time, Channels, Mels]\n",
    "        x = x.flatten(2)           # [B, Time, Channels * Mels]\n",
    "        \n",
    "        # LSTM processing\n",
    "        lstm_out, _ = self.lstm(x)  # [B, Time, 256]\n",
    "        \n",
    "        # Use last output\n",
    "        x = lstm_out[:, -1, :]  # [B, 256]\n",
    "        \n",
    "        # Classification\n",
    "        return self.fc(x).squeeze()\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze()\n",
    "\n",
    "print(\"Models defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b5ec94",
   "metadata": {},
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065606f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, model_name, epochs=50, patience=7):\n",
    "    \"\"\"Generic training function\"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for batch_x, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            correct_train += (preds == batch_y.bool()).sum().item()\n",
    "            total_train += batch_y.numel()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = torch.sigmoid(outputs) > 0.5\n",
    "                correct_val += (preds == batch_y.bool()).sum().item()\n",
    "                total_val += batch_y.numel()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = correct_val / total_val * 100\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, \"\n",
    "              f\"Train Acc = {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss = {avg_val_loss:.4f}, Val Acc = {val_accuracy:.2f}%\")\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), os.path.join(MODEL_DIR, f\"{model_name}_best.pth\"))\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, model_name):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    model.eval()\n",
    "    test_preds, test_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            test_preds.extend(probs)\n",
    "            test_labels.extend(batch_y.numpy())\n",
    "    \n",
    "    test_preds = np.array(test_preds)\n",
    "    test_labels = np.array(test_labels)\n",
    "    pred_binary = test_preds > 0.5\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(test_labels, pred_binary),\n",
    "        'precision': precision_score(test_labels, pred_binary),\n",
    "        'recall': recall_score(test_labels, pred_binary),\n",
    "        'f1': f1_score(test_labels, pred_binary),\n",
    "        'auc': roc_auc_score(test_labels, test_preds)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name} Test Results:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "    \n",
    "    return test_preds, test_labels, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c40dba1",
   "metadata": {},
   "source": [
    "### Train CNN+BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrogram dataset size: 800\n",
      "Embedding dataset size: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\BE Project\\Self\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN_BiLSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 90/90 [00:23<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6926, Train Acc = 51.67%, Val Loss = 0.7020, Val Acc = 46.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 90/90 [00:09<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.6548, Train Acc = 62.92%, Val Loss = 0.5882, Val Acc = 68.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 90/90 [00:09<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.5813, Train Acc = 69.17%, Val Loss = 0.6943, Val Acc = 66.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 90/90 [00:08<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.4972, Train Acc = 75.56%, Val Loss = 0.3407, Val Acc = 86.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 90/90 [00:08<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.3045, Train Acc = 87.08%, Val Loss = 0.0846, Val Acc = 98.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 90/90 [00:09<00:00,  9.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 0.1538, Train Acc = 92.92%, Val Loss = 0.8401, Val Acc = 72.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 90/90 [00:08<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 0.1622, Train Acc = 94.17%, Val Loss = 0.1828, Val Acc = 93.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 90/90 [00:10<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 0.0456, Train Acc = 98.75%, Val Loss = 0.2488, Val Acc = 91.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 90/90 [00:09<00:00,  9.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 0.1024, Train Acc = 97.08%, Val Loss = 0.0099, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 90/90 [00:07<00:00, 11.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 0.0191, Train Acc = 99.58%, Val Loss = 0.0024, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 90/90 [00:07<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss = 0.0029, Train Acc = 100.00%, Val Loss = 0.0005, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 90/90 [00:08<00:00, 10.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss = 0.0008, Train Acc = 100.00%, Val Loss = 0.0002, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 90/90 [00:09<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss = 0.0014, Train Acc = 100.00%, Val Loss = 0.0001, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 90/90 [00:10<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss = 0.0005, Train Acc = 100.00%, Val Loss = 0.0000, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 90/90 [00:11<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss = 0.0003, Train Acc = 100.00%, Val Loss = 0.0000, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 90/90 [00:11<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss = 0.0001, Train Acc = 100.00%, Val Loss = 0.0000, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 90/90 [00:13<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss = 0.0001, Train Acc = 100.00%, Val Loss = 0.0000, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 90/90 [00:15<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss = 0.0001, Train Acc = 100.00%, Val Loss = 0.0000, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 90/90 [00:16<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss = 0.0219, Train Acc = 99.72%, Val Loss = 0.6945, Val Acc = 82.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 90/90 [00:16<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss = 0.1249, Train Acc = 96.25%, Val Loss = 0.1666, Val Acc = 92.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 90/90 [00:14<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss = 0.1003, Train Acc = 96.53%, Val Loss = 0.0193, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 90/90 [00:14<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss = 0.0523, Train Acc = 98.61%, Val Loss = 0.0075, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 90/90 [00:15<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss = 0.0077, Train Acc = 99.86%, Val Loss = 0.0036, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 90/90 [00:15<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss = 0.0051, Train Acc = 100.00%, Val Loss = 0.0026, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 90/90 [00:15<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss = 0.0033, Train Acc = 100.00%, Val Loss = 0.0022, Val Acc = 100.00%\n",
      "Early stopping triggered.\n",
      "\n",
      "CNN+BiLSTM Test Results:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1: 1.0000\n",
      "Auc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Create datasets and data loaders\n",
    "spec_dataset = SpectrogramDataset(SPECTROGRAM_DIR)\n",
    "embed_dataset = EmbeddingDataset(EMBEDDING_DIR)\n",
    "\n",
    "print(f\"Spectrogram dataset size: {len(spec_dataset)}\")\n",
    "print(f\"Embedding dataset size: {len(embed_dataset)}\")\n",
    "\n",
    "# New 90% train, 10% test split\n",
    "torch.manual_seed(42)\n",
    "spec_lengths = [int(0.9 * len(spec_dataset))]\n",
    "spec_lengths.append(len(spec_dataset) - sum(spec_lengths))  # 10%\n",
    "spec_train, spec_test = random_split(spec_dataset, spec_lengths)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "embed_lengths = [int(0.9 * len(embed_dataset))]\n",
    "embed_lengths.append(len(embed_dataset) - sum(embed_lengths))  # 10%\n",
    "embed_train, embed_test = random_split(embed_dataset, embed_lengths)\n",
    "\n",
    "# Create data loaders\n",
    "spec_train_loader = DataLoader(spec_train, batch_size=8, shuffle=True)\n",
    "spec_val_loader = DataLoader(spec_test, batch_size=8)  # test set used as validation\n",
    "spec_test_loader = DataLoader(spec_test, batch_size=8)\n",
    "\n",
    "# Train CNN+BiLSTM model\n",
    "cnn_bilstm = CNN_BiLSTM(n_mels=N_MELS)\n",
    "cnn_losses = train_model(cnn_bilstm, spec_train_loader, spec_val_loader, \"CNN_BiLSTM\", epochs=30)\n",
    "\n",
    "# Load best model and evaluate\n",
    "cnn_bilstm.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"CNN_BiLSTM_best.pth\")))\n",
    "cnn_bilstm = cnn_bilstm.to(device)\n",
    "cnn_preds, cnn_labels, cnn_metrics = evaluate_model(cnn_bilstm, spec_test_loader, \"CNN+BiLSTM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a58b4",
   "metadata": {},
   "source": [
    "### Train wav2vec+MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932bca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n",
      "\n",
      "Training wav2vec_MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 23/23 [00:12<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.6910, Train Acc = 52.64%, Val Loss = 0.6964, Val Acc = 42.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 23/23 [00:00<00:00, 43.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.6564, Train Acc = 61.94%, Val Loss = 0.5944, Val Acc = 68.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 23/23 [00:00<00:00, 33.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.5052, Train Acc = 76.53%, Val Loss = 0.2849, Val Acc = 96.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 23/23 [00:00<00:00, 30.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.2447, Train Acc = 91.67%, Val Loss = 0.1469, Val Acc = 95.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 23/23 [00:00<00:00, 33.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.1292, Train Acc = 94.72%, Val Loss = 0.0407, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 23/23 [00:00<00:00, 30.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 0.0630, Train Acc = 97.64%, Val Loss = 0.1297, Val Acc = 96.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 23/23 [00:00<00:00, 37.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 0.0853, Train Acc = 96.53%, Val Loss = 0.4877, Val Acc = 81.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 23/23 [00:00<00:00, 36.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 0.1445, Train Acc = 93.47%, Val Loss = 0.0851, Val Acc = 97.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 23/23 [00:00<00:00, 34.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 0.0369, Train Acc = 98.61%, Val Loss = 0.0346, Val Acc = 98.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 23/23 [00:00<00:00, 31.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 0.0231, Train Acc = 99.03%, Val Loss = 0.0450, Val Acc = 98.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 23/23 [00:00<00:00, 43.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss = 0.0167, Train Acc = 99.44%, Val Loss = 0.0080, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 23/23 [00:00<00:00, 38.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss = 0.0116, Train Acc = 99.72%, Val Loss = 0.0029, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 23/23 [00:00<00:00, 45.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss = 0.0188, Train Acc = 99.31%, Val Loss = 0.0084, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 23/23 [00:00<00:00, 47.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss = 0.0290, Train Acc = 98.61%, Val Loss = 0.0457, Val Acc = 97.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 23/23 [00:00<00:00, 57.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss = 0.0654, Train Acc = 97.92%, Val Loss = 0.0247, Val Acc = 98.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 23/23 [00:00<00:00, 48.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss = 0.0301, Train Acc = 99.31%, Val Loss = 0.0103, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 23/23 [00:00<00:00, 58.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss = 0.0122, Train Acc = 99.58%, Val Loss = 0.0147, Val Acc = 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 23/23 [00:00<00:00, 44.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss = 0.0083, Train Acc = 100.00%, Val Loss = 0.0233, Val Acc = 98.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 23/23 [00:00<00:00, 43.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss = 0.0116, Train Acc = 99.72%, Val Loss = 0.0064, Val Acc = 100.00%\n",
      "Early stopping triggered.\n",
      "\n",
      "wav2vec+MLP Test Results:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1: 1.0000\n",
      "Auc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# New 90% train / 10% test split for embeddings\n",
    "torch.manual_seed(42)\n",
    "embed_lengths = [int(0.9 * len(embed_dataset))]\n",
    "embed_lengths.append(len(embed_dataset) - sum(embed_lengths))  # 10%\n",
    "embed_train, embed_test = random_split(embed_dataset, embed_lengths)\n",
    "\n",
    "# Create data loaders\n",
    "embed_train_loader = DataLoader(embed_train, batch_size=32, shuffle=True)\n",
    "embed_val_loader = DataLoader(embed_test, batch_size=32)  # using test as val\n",
    "embed_test_loader = DataLoader(embed_test, batch_size=32)\n",
    "\n",
    "# Get embedding dimension\n",
    "sample_embedding = embed_dataset[0][0]\n",
    "embedding_dim = int(sample_embedding.shape[0])\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "\n",
    "# Train MLP model\n",
    "mlp_model = MLPClassifier(embedding_dim)\n",
    "mlp_losses = train_model(mlp_model, embed_train_loader, embed_val_loader, \"wav2vec_MLP\", epochs=30)\n",
    "\n",
    "# Load best model and evaluate\n",
    "mlp_model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"wav2vec_MLP_best.pth\")))\n",
    "mlp_model = mlp_model.to(device)\n",
    "mlp_preds, mlp_labels, mlp_metrics = evaluate_model(mlp_model, embed_test_loader, \"wav2vec+MLP\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd0bf9e",
   "metadata": {},
   "source": [
    "### Create Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4546412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best ensemble weight (α): 0.000\n",
      "Best validation F1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def find_best_ensemble_weight(val_preds_1, val_preds_2, val_labels):\n",
    "    \"\"\"Find optimal ensemble weight using validation set\"\"\"\n",
    "    best_f1 = 0\n",
    "    best_alpha = 0.5\n",
    "    \n",
    "    for alpha in np.arange(0.0, 1.05, 0.05):\n",
    "        ensemble_preds = alpha * val_preds_1 + (1 - alpha) * val_preds_2\n",
    "        ensemble_binary = ensemble_preds > 0.5\n",
    "        f1 = f1_score(val_labels, ensemble_binary)\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_alpha = alpha\n",
    "    \n",
    "    return best_alpha, best_f1\n",
    "\n",
    "# Get predictions on validation set for ensemble tuning\n",
    "cnn_bilstm.eval()\n",
    "mlp_model.eval()\n",
    "\n",
    "val_preds_cnn, val_preds_mlp = [], []\n",
    "val_labels_ensemble = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # CNN predictions on validation set\n",
    "    for batch_x, batch_y in spec_val_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        outputs = torch.sigmoid(cnn_bilstm(batch_x)).cpu().numpy()\n",
    "        val_preds_cnn.extend(outputs)\n",
    "        val_labels_ensemble.extend(batch_y.numpy())\n",
    "    \n",
    "    # MLP predictions on validation set\n",
    "    val_labels_mlp = []\n",
    "    for batch_x, batch_y in embed_val_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        outputs = torch.sigmoid(mlp_model(batch_x)).cpu().numpy()\n",
    "        val_preds_mlp.extend(outputs)\n",
    "        val_labels_mlp.extend(batch_y.numpy())\n",
    "\n",
    "val_preds_cnn = np.array(val_preds_cnn)\n",
    "val_preds_mlp = np.array(val_preds_mlp)\n",
    "\n",
    "# Find best ensemble weight\n",
    "best_alpha, best_val_f1 = find_best_ensemble_weight(val_preds_cnn, val_preds_mlp, val_labels_ensemble)\n",
    "print(f\"\\nBest ensemble weight (α): {best_alpha:.3f}\")\n",
    "print(f\"Best validation F1: {best_val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd0455d",
   "metadata": {},
   "source": [
    "### Evaluate Ensemble on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ENSEMBLE MODEL TEST RESULTS\n",
      "==================================================\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1: 1.0000\n",
      "Auc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Get test predictions from both models\n",
    "test_preds_cnn, test_preds_mlp = [], []\n",
    "test_labels_ensemble = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # CNN predictions on test set\n",
    "    for batch_x, batch_y in spec_test_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        outputs = torch.sigmoid(cnn_bilstm(batch_x)).cpu().numpy()\n",
    "        test_preds_cnn.extend(outputs)\n",
    "        test_labels_ensemble.extend(batch_y.numpy())\n",
    "    \n",
    "    # MLP predictions on test set\n",
    "    for batch_x, batch_y in embed_test_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        outputs = torch.sigmoid(mlp_model(batch_x)).cpu().numpy()\n",
    "        test_preds_mlp.extend(outputs)\n",
    "\n",
    "test_preds_cnn = np.array(test_preds_cnn)\n",
    "test_preds_mlp = np.array(test_preds_mlp)\n",
    "\n",
    "# Create ensemble predictions\n",
    "ensemble_preds = best_alpha * test_preds_cnn + (1 - best_alpha) * test_preds_mlp\n",
    "ensemble_binary = ensemble_preds > 0.5\n",
    "\n",
    "# Calculate ensemble metrics\n",
    "ensemble_metrics = {\n",
    "    'accuracy': accuracy_score(test_labels_ensemble, ensemble_binary),\n",
    "    'precision': precision_score(test_labels_ensemble, ensemble_binary),\n",
    "    'recall': recall_score(test_labels_ensemble, ensemble_binary),\n",
    "    'f1': f1_score(test_labels_ensemble, ensemble_binary),\n",
    "    'auc': roc_auc_score(test_labels_ensemble, ensemble_preds)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ENSEMBLE MODEL TEST RESULTS\")\n",
    "print(\"=\"*50)\n",
    "for metric, value in ensemble_metrics.items():\n",
    "    print(f\"{metric.capitalize()}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d1fe1c",
   "metadata": {},
   "source": [
    "### Save Complete Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete ensemble model saved to: D:\\BE Project\\Self\\APPROACH3-CNN-BiLSTM\\models\\complete_ensemble_model.pth\n"
     ]
    }
   ],
   "source": [
    "class EnsembleModel:\n",
    "    def __init__(self, cnn_model, mlp_model, wav2vec_model, alpha, device):\n",
    "        self.cnn_model = cnn_model\n",
    "        self.mlp_model = mlp_model\n",
    "        self.wav2vec_model = wav2vec_model\n",
    "        self.alpha = alpha\n",
    "        self.device = device\n",
    "        \n",
    "        # Set models to eval mode\n",
    "        self.cnn_model.eval()\n",
    "        self.mlp_model.eval()\n",
    "        self.wav2vec_model.eval()\n",
    "    \n",
    "    def predict_audio_file(self, audio_path):\n",
    "        \"\"\"Predict single audio file using ensemble\"\"\"\n",
    "        # Generate spectrogram\n",
    "        y, sr = librosa.load(audio_path, sr=SAMPLE_RATE, mono=True)\n",
    "        y = librosa.util.fix_length(y, size=SEGMENT_SAMPLES)\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=y, sr=sr, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH\n",
    "        )\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        mel_spec_norm = (mel_spec_db - mel_spec_db.mean()) / (mel_spec_db.std() + 1e-8)\n",
    "        spec_tensor = torch.tensor(mel_spec_norm, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        # Generate wav2vec embedding\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        if sr != 16000:\n",
    "            waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n",
    "        \n",
    "        waveform = waveform.to(self.device)\n",
    "        with torch.inference_mode():\n",
    "            features, _ = self.wav2vec_model(waveform)\n",
    "            embedding = features.mean(dim=1).squeeze().unsqueeze(0)\n",
    "        \n",
    "        # Get predictions from both models\n",
    "        with torch.no_grad():\n",
    "            spec_tensor = spec_tensor.to(self.device)\n",
    "            cnn_pred = torch.sigmoid(self.cnn_model(spec_tensor)).cpu().item()\n",
    "            mlp_pred = torch.sigmoid(self.mlp_model(embedding)).cpu().item()\n",
    "        \n",
    "        # Ensemble prediction\n",
    "        ensemble_pred = self.alpha * cnn_pred + (1 - self.alpha) * mlp_pred\n",
    "        \n",
    "        return {\n",
    "            'ensemble_score': ensemble_pred,\n",
    "            'cnn_score': cnn_pred,\n",
    "            'mlp_score': mlp_pred,\n",
    "            'prediction': 'FAKE' if ensemble_pred > 0.5 else 'REAL'\n",
    "        }\n",
    "\n",
    "# Create ensemble model\n",
    "ensemble_model = EnsembleModel(cnn_bilstm, mlp_model, model_wav2vec, best_alpha, device)\n",
    "\n",
    "def cast_all(obj):\n",
    "    \"\"\"Recursively convert NumPy types to standard Python types.\"\"\"\n",
    "    import numbers\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: cast_all(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        return type(obj)(cast_all(v) for v in obj)\n",
    "    elif isinstance(obj, (np.integer,)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (numbers.Real,)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "\n",
    "# Save ensemble model\n",
    "ensemble_save_dict = {\n",
    "    'cnn_state_dict': cnn_bilstm.state_dict(),\n",
    "    'mlp_state_dict': mlp_model.state_dict(),\n",
    "    'alpha': float(best_alpha),\n",
    "    'embedding_dim': int(embedding_dim),\n",
    "    'model_config': {\n",
    "        'n_mels': int(N_MELS),\n",
    "        'sample_rate': int(SAMPLE_RATE),\n",
    "        'duration': int(DURATION),\n",
    "        'n_fft': int(N_FFT),\n",
    "        'hop_length': int(HOP_LENGTH)\n",
    "    },\n",
    "    'metrics': cast_all({\n",
    "    'cnn_metrics': cnn_metrics,\n",
    "    'mlp_metrics': mlp_metrics,\n",
    "    'ensemble_metrics': ensemble_metrics\n",
    "})\n",
    "\n",
    "}\n",
    "\n",
    "torch.save(ensemble_save_dict, os.path.join(MODEL_DIR, 'complete_ensemble_model.pth'))\n",
    "print(f\"\\nComplete ensemble model saved to: {os.path.join(MODEL_DIR, 'complete_ensemble_model.pth')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df86c37",
   "metadata": {},
   "source": [
    "### Test Ensemble on Sample Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fed81fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING ENSEMBLE ON SAMPLE FILES\n",
      "============================================================\n",
      "\n",
      "File: D:\\BE Project\\Self\\APPROACH3-CNN-BiLSTM\\AI Voice Aaditya.wav\n",
      "Prediction: FAKE\n",
      "Ensemble Score: 1.0000\n",
      "CNN Score: 1.0000\n",
      "MLP Score: 1.0000\n",
      "\n",
      "File: D:\\BE Project\\Self\\APPROACH3-CNN-BiLSTM\\omkar_new_test_real.wav\n",
      "Prediction: REAL\n",
      "Ensemble Score: 0.0000\n",
      "CNN Score: 0.0000\n",
      "MLP Score: 0.0000\n",
      "\n",
      "File: D:\\BE Project\\Self\\APPROACH3-CNN-BiLSTM\\omkar_real.wav\n",
      "Prediction: REAL\n",
      "Ensemble Score: 0.0001\n",
      "CNN Score: 0.0000\n",
      "MLP Score: 0.0001\n",
      "\n",
      "File: D:\\BE Project\\Self\\APPROACH3-CNN-BiLSTM\\Real Voice Aaditya.wav\n",
      "Prediction: REAL\n",
      "Ensemble Score: 0.0095\n",
      "CNN Score: 0.0000\n",
      "MLP Score: 0.0095\n",
      "\n",
      "✅ Training complete! Your ensemble model is ready for use.\n"
     ]
    }
   ],
   "source": [
    "# sample_files = [\n",
    "#     \"1_original_shree.wav\",\n",
    "#     \"1_fake_aaditya.wav\", \n",
    "#     \"1_fake_jui.wav\",\n",
    "#     \"1_original_omkar.wav\"\n",
    "# ]\n",
    "\n",
    "sample_files = [\n",
    "    \"D:\\BE Project\\Self\\APPROACH3-CNN-BiLSTM\\AI Voice Aaditya.wav\",\n",
    "    \"D:\\BE Project\\Self\\APPROACH3-CNN-BiLSTM\\omkar_new_test_real.wav\", \n",
    "    \"D:\\BE Project\\Self\\APPROACH3-CNN-BiLSTM\\omkar_real.wav\",\n",
    "    \"D:\\BE Project\\Self\\APPROACH3-CNN-BiLSTM\\Real Voice Aaditya.wav\",\n",
    "    \n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING ENSEMBLE ON SAMPLE FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for filename in sample_files:\n",
    "    file_path = os.path.join(AUDIO_DIR, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            result = ensemble_model.predict_audio_file(file_path)\n",
    "            print(f\"\\nFile: {filename}\")\n",
    "            print(f\"Prediction: {result['prediction']}\")\n",
    "            print(f\"Ensemble Score: {result['ensemble_score']:.4f}\")\n",
    "            print(f\"CNN Score: {result['cnn_score']:.4f}\")\n",
    "            print(f\"MLP Score: {result['mlp_score']:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "    else:\n",
    "        print(f\"File not found: {filename}\")\n",
    "\n",
    "print(\"\\n✅ Training complete! Your ensemble model is ready for use.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f693b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245c5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e13279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
